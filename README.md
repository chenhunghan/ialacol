# ialacol (reads: localai)

ğŸ¦„ Self hosted, ğŸ”’ private, ğŸŸ scalable, ğŸ¤‘ commercially usable, ğŸ’¬ LLM chat streaming service with 1-click Kubernetes cluster installation on any cloud

This project is inspired by [LocalAI]<https://github.com/go-skynet/LocalAI>, [privateGPT](https://github.com/imartinez/privateGPT), [local.ai](https://github.com/louisgv/local.ai), [llama-cpp-python](https://github.com/abetlen/llama-cpp-python), [closedai](https://github.com/closedai-project/closedai), [closedai](https://github.com/closedai-project/closedai), [mlc-llm](https://github.com/mlc-ai/mlc-llm), but with a focus on Kubernetes deployment, streaming, and commercially usable models only.

## Development

```sh
python3 -m venv .venv
source .venv/bin/activate
python3 -m pip install -r requirements.txt
pip freeze > requirements.txt
```
